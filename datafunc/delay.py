import time, random
import os, glob
import csv, json
import numpy as np
import matplotlib.pyplot as plt

"""
This file takes the CSVs generated by GETPREDICTIONS.PY and calculates delays
(and other potentially useful statistics) for each stop, line, and stop AND line.
Recall that there can be multiple lines at each stop, so that third category is
very important.

INPUT: predictions/*.csv
OUTPUT: data.json
"""

countdown = 20

all_trips = []

by_stop_line = {}
by_stop = {}
by_line = {}

def aggregate(filename):
    split = filename[12:].split("_")
    stop = split[0]
    line = split[1] + "_" + split[2][:-4]
    name = stop + "_" + line
    # keep prediction times for each trip for each day
    pre_dict = {}
    min_dict = {}

    with open(filename, 'r') as csvfile:
        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')
        for row in reader:
            if row[5] == "tripTag":
                continue
            # a bus trip's tripTag is only unique BY DAY
            p = time.localtime(int(row[0][:-3]))
            trip_day = str(p.tm_yday) + "-" + row[5]
            if trip_day not in pre_dict.keys():
                pre_dict[trip_day] = [p]
                min_dict[trip_day] = [row[2]]
            else:
                pre_dict[trip_day].append(p)
                min_dict[trip_day].append(row[2])
    # calculate arrival and prediction times for each stop
    trips = {}
    trips_alt = {}
    for t in pre_dict.keys():
        data = {}
        until = 90
        i = 0
        # choose prediction to compare against using min_dict
        while i < len(min_dict[t]):
            if int(min_dict[t][i]) < countdown:
                break
            until = int(min_dict[t][i])
            i += 1
        # compare arrival with prediction using pre_dict
        difference = time.mktime(pre_dict[t][-1]) - time.mktime(pre_dict[t][i-1])
        if until < 90 and abs(difference) < countdown * 60: #ignore differences greater than prediction
            data['arrival'] = pre_dict[t][-1]
            data['prediction'] = pre_dict[t][i-1]
            data['delay'] = difference
            if until == countdown:
                data['sample'] = "{0:.2f}".format((countdown * 60 + difference) / 60)
            trips[t] = data
            trips_alt[t + "_" + stop] = data
    by_stop_line[name] = trips
    if stop in by_stop.keys():
        by_stop[stop].update(trips)
    else:
        by_stop[stop] = trips
    if line in by_line.keys():
        by_line[line].update(trips_alt)
    else:
        by_line[line] = trips_alt

# each of these returns summary stats, as well as delays in chronological order
def get_stats(database, query):
    stats = {}
    times = []
    delays = []
    sample_ontime = []
    sample_delayed = []
    time_to_delay = {}
    late = 0
    hist_data = [0] * 38; #30 min time intervals from 5AM to 12AM
    entries = database[query]
    for i in entries.keys():
        t = entries[i]['arrival']
        d = entries[i]['delay']
        times.append(t)
        delays.append(d)
        minutes = t[3] * 60 + t[4] # minutes since midnight
        index = (minutes - 300) // 30 # which 30 min time interval from 5AM (300 min)
        if index < 0:
            index = 0
        if index > 37: # 38 bins in total, 37th is last
            index = 37
        # increment count if late
        if (d > 300): # 5 minutes
            late += 1
            hist_data[index] += 1
            if 'sample' in entries[i].keys():
                sample_delayed.append(entries[i]['sample'])
        else:
            if 'sample' in entries[i].keys():
                sample_ontime.append(entries[i]['sample'])

    stats['mean'] = np.mean(delays)
    stats['median'] = np.median(delays)
    stats['std'] = np.std(delays)
    stats['late'] = late
    stats['length'] = len(delays)
    stats['hist'] = hist_data
    # calculate percent that are significantly delayed (>= 300 sec)
    delayed = int(float(stats['late']) / stats['length'] * 100)
    delayedBins = []
    regularBins = []
    while len(delayedBins) < delayed:
        i = random.randint(0, len(sample_delayed) - 1)
        delayedBins.append(sample_delayed[i])
    while len(regularBins) < 100 - delayed:
        i = random.randint(0, len(sample_ontime) - 1)
        regularBins.append(sample_ontime[i])
    stats['sample'] = delayedBins + regularBins
    return stats

# utility functions
def sformat(seconds):
    return "%02d:%02d" % (int(seconds) // 60, int(seconds) % 60)

def sort_by_time(time):
    return time[3] * 10000 + time[4] * 1000 + time[5]

def main():
    summary = {}
    print("START AT " + time.strftime('%X %x %Z'))

    print("Aggregating data from ACTransit polling...")
    # aggregate("predictions/50444_51B_Berkeley Amtrak.csv")
    for filename in glob.glob("predictions/*_*.csv"):
        if "_800_" in filename or "_851_" in filename:
            continue
        aggregate(filename)
        print("\t- " + filename)
    print("Aggregation complete.")

    # print(by_stop_line["50400_65_To Senior Ave. loop"])
    print("Calculating statistics by stop and line...")
    for sl in by_stop_line.keys():
        stats = get_stats(by_stop_line, sl)
        summary[sl] = stats
        print("\t- " + sl)
    print("Calculation 1/3 complete.")

    print("Calculating statistics by stop...")
    for s in by_stop.keys():
        stats = get_stats(by_stop, s)
        summary[s] = stats
        print("\t- " + s)
    print("Calculation 2/3 complete.")

    print("Calculating statistics by line...")
    for l in by_line.keys():
        stats = get_stats(by_line, l)
        summary[l] = stats
        print("\t- " + l)
    print("Calculation 3/3 complete.")

    summary['timeslots'] = ['5am','6am','7am','8am','9am','10am','11am','12pm','1pm','2pm','3pm','4pm','5pm','6pm','7pm','8pm','9pm','10pm','11pm','12am'];

    with open('data.json', 'w') as fp:
        json.dump(summary, fp)

    print("END AT " + time.strftime('%X %x %Z'))
    trip_set = set(all_trips);
    print(len(trip_set));
    print(trip_set);
main()
